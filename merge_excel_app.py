import os
import re
import json
import datetime
import stat
from pathlib import Path
from difflib import SequenceMatcher
import tkinter as tk
from tkinter import ttk, filedialog, messagebox

import pandas as pd

try:
    from openpyxl import load_workbook
except Exception:
    load_workbook = None


def set_file_readonly(filepath: Path, readonly: bool = True):
    """Set or remove read-only flag on a file."""
    try:
        if readonly:
            # Remove write permissions
            os.chmod(filepath, stat.S_IRUSR | stat.S_IRGRP | stat.S_IROTH)
        else:
            # Add write permissions
            os.chmod(filepath, stat.S_IRUSR | stat.S_IWUSR | stat.S_IRGRP | stat.S_IROTH)
    except Exception:
        pass


def is_file_readonly(filepath: Path) -> bool:
    """Check if a file is read-only (no write permission)."""
    try:
        if not filepath.exists():
            return False
        mode = os.stat(filepath).st_mode
        return not (mode & stat.S_IWUSR)
    except Exception:
        return False


# -------------------------
# Persistent storage paths
# -------------------------
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"
ORDERS_DIR = None  # –ù–µ —Å–µ –∏–∑–ø–æ–ª–∑–≤–∞ - –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è—Ç –∏–∑–±–∏—Ä–∞ –∫—ä–¥–µ –¥–∞ –∑–∞–ø–∏—Å–≤–∞
PROTOCOLS_DIR = None  # –©–µ —Å–µ –∑–∞–¥–∞–¥–µ –æ—Ç –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è
SETTINGS_FILE = DATA_DIR / "settings.json"


# -------------------------
# Helpers: header detection
# -------------------------
def normalize(s: str) -> str:
    """Normalize a header or key: lowercase, remove punctuation and collapse whitespace.
    This makes matching more robust for variants like '—à–∏—Ä./–≤–∏—Å.' vs '—à–∏—Ä/–≤–∏—Å'.
    """
    s = str(s).strip().lower()
    # replace any non-word/digit characters with a single space (keeps Cyrillic/latin letters and digits)
    s = re.sub(r"[^\w\d]+", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s
def canonical_code(x) -> str:
    """
    –ö–∞–Ω–æ–Ω–∏–∑–∏—Ä–∞ –∫–æ–¥/–∞—Ä—Ç–∏–∫—É–ª –∑–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ–∂–¥—É —Ç–∞–±–ª–∏—Ü–∏.
    - –º–∞—Ö–∞ .0 (–∞–∫–æ Excel –≥–æ –µ –ø—Ä–æ—á–µ–ª –∫–∞—Ç–æ float)
    - –º–∞—Ö–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∏ / NBSP
    - –ø—Ä–∞–≤–∏ upper()
    """
    if pd.isna(x):
        return ""
    # –∞–∫–æ –µ float –∏ –µ —Ü—è–ª–æ —á–∏—Å–ª–æ -> int
    if isinstance(x, float) and x.is_integer():
        x = int(x)
    s = str(x).strip()
    # –º–∞—Ö–Ω–∏ .0 –∞–∫–æ –∏–¥–≤–∞ –æ—Ç float –≤ —Ç–µ–∫—Å—Ç
    if re.fullmatch(r"\d+\.0", s):
        s = s[:-2]
    # –º–∞—Ö–Ω–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∏ –∏ NBSP
    s = re.sub(r"[\s\u00A0\u202F]+", "", s)
    return s.upper()


def fuzzy_match_best(item: str, candidates: list, threshold: float = 0.6):
    """
    Find the best fuzzy match for `item` among `candidates`.
    Returns (best_candidate, score) or (None, 0) if no match above threshold.
    """
    item_lower = item.lower()
    best = None
    best_score = 0
    for c in candidates:
        if not isinstance(c, str):
            continue
        score = SequenceMatcher(None, item_lower, c.lower()).ratio()
        if score > best_score:
            best_score = score
            best = c
    if best_score >= threshold:
        return best, best_score
    return None, 0


def to_float(x):
    """
    –ü–æ–¥–æ–±—Ä–µ–Ω float parser:
    - –ø—Ä–∏–µ–º–∞ '0,85', '0.85', '0,85 –ª–≤', '‚Ç¨0.85', '1 234,56'
    - –≤–∞–¥–∏ –ø—ä—Ä–≤–æ—Ç–æ —á–∏—Å–ª–æ –æ—Ç —Ç–µ–∫—Å—Ç–∞
    """
    if pd.isna(x):
        return None
    if isinstance(x, (int, float)):
        return float(x)

    s = str(x).strip()
    if not s:
        return None

    # –º–∞—Ö–Ω–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∏/—Ö–∏–ª—è–¥–∞—Ä–Ω–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
    s = re.sub(r"[\s\u00A0\u202F]+", "", s)

    # –≤–∑–µ–º–∏ –ø—ä—Ä–≤–æ—Ç–æ —á–∏—Å–ª–æ (—Å , –∏–ª–∏ .)
    m = re.search(r"[-+]?\d+(?:[.,]\d+)?", s)
    if not m:
        return None

    num = m.group(0).replace(",", ".")
    try:
        return float(num)
    except Exception:
        return None


def parse_qty_range_from_header(header: str):
    """
    –ò–∑–≤–ª–∏—á–∞ (min,max) –æ—Ç –∑–∞–≥–ª–∞–≤–∏—è –∫–∞—Ç–æ:
      '1 000 - 1 999', '2000-2999', '1 000 ‚Äì1 999 –±—Ä'
    """
    if header is None:
        return None
    s = str(header).replace("‚Äì", "-").replace("‚Äî", "-")

    parts = re.findall(r"\d[\d\s\u00A0\u202F\.,]*\d|\d+", s)
    nums = []
    for p in parts:
        digits = re.sub(r"[^0-9]", "", p)
        if digits:
            try:
                nums.append(int(digits))
            except Exception:
                pass

    if len(nums) >= 2:
        return nums[0], nums[1]
    return None


def detect_range_columns(df_prices: pd.DataFrame):
    ranges = []
    for c in df_prices.columns:
        rng = parse_qty_range_from_header(c)
        if rng:
            ranges.append((rng[0], rng[1], c))
    ranges.sort(key=lambda x: (x[0], x[1]))
    return ranges


def resolve_unit_price_from_ranges(qty: int, price_row: pd.Series, ranges):
    if not ranges:
        return None

    for min_q, max_q, col in ranges:
        if min_q <= qty <= max_q:
            return to_float(price_row.get(col))

    # qty –Ω–∞–¥ –ø–æ—Å–ª–µ–¥–Ω–∏—è –¥–∏–∞–ø–∞–∑–æ–Ω -> –ø–æ–ª–∑–≤–∞–π –ø–æ—Å–ª–µ–¥–Ω–∏—è
    last_min, last_max, last_col = ranges[-1]
    if qty > last_max:
        return to_float(price_row.get(last_col))

    return None


def find_column(df: pd.DataFrame, candidates):
    """
    Find a column by checking if any candidate substring appears in the header.
    Returns column name or raises ValueError.
    """
    cols = list(df.columns)
    norm_cols = {c: normalize(c) for c in cols}
    cand_norm = [normalize(x) for x in candidates]

    for c in cols:
        h = norm_cols[c]
        if any(cn in h for cn in cand_norm):
            return c
    raise ValueError(f"–ù–µ –Ω–∞–º–µ—Ä–∏—Ö –∫–æ–ª–æ–Ω–∞ –∑–∞: {candidates}. –ù–∞–ª–∏—á–Ω–∏ –∫–æ–ª–æ–Ω–∏: {cols}")


def to_int(x):
    if pd.isna(x):
        return None
    if isinstance(x, (int,)):
        return int(x)
    try:
        s = str(x).strip()
        # remove thousands separators (spaces, NBSP)
        s = re.sub(r"[\s\u00A0\u202F]+", "", s)
        s = s.replace(",", ".")
        v = float(s)
        return int(round(v))
    except Exception:
        return None




def excel_cell_to_string(x) -> str:
    """Return value exactly as string from Excel (no parsing/formatting)."""
    if pd.isna(x):
        return ""
    return str(x).strip()


# -------------------------
# NEW: price ranges like "1 000 - 1 999"
# -------------------------
def parse_qty_range_from_header(header):
    """
    Extract (min,max) from headers like:
      "1 000 -1 999", "2 000 - 2 999", "1000-1999", "1 000 ‚Äì 1 999"
      Also handles single numbers like 50000 -> (50000, 59999)
    Returns (min,max) or None.
    """
    if header is None:
        return None
    
    # If header is already a number
    if isinstance(header, (int, float)) and not pd.isna(header):
        qty = int(header)
        # Single number: treat as exact quantity with some range
        # e.g., 50000 means 50000-59999, 60000 means 60000-79999, etc.
        return (qty, qty)  # Will be handled specially in resolve_unit_price
    
    s = str(header).replace("‚Äì", "-").replace("‚Äî", "-")

    # find numbers possibly containing spaces/dots/commas (thousand separators)
    parts = re.findall(r"\d[\d\s\u00A0\u202F\.,]*\d|\d+", s)
    nums = []
    for p in parts:
        digits = re.sub(r"[^0-9]", "", p)
        if digits:
            try:
                nums.append(int(digits))
            except Exception:
                pass
    if len(nums) >= 2:
        return nums[0], nums[1]
    elif len(nums) == 1:
        # Single number in header text
        return (nums[0], nums[0])
    return None


def detect_range_columns(df_prices: pd.DataFrame):
    """
    Finds range-price columns in prices sheet and returns:
      [(min_qty, max_qty, colname), ...] sorted by min_qty.
    Also detects single-number columns like 50000, 60000.
    """
    ranges = []
    for c in df_prices.columns:
        rng = parse_qty_range_from_header(c)
        if rng:
            ranges.append((rng[0], rng[1], c))
    ranges.sort(key=lambda x: (x[0], x[1]))
    return ranges


def resolve_unit_price_from_ranges(qty: int, price_row: pd.Series, ranges):
    """
    Pick unit price by finding the column whose (min<=qty<=max).
    For single-number columns, picks the closest one that doesn't exceed qty.
    If qty is above the last range, use the last range's price (fallback).
    If qty is below the first range, use the first range's price (fallback).
    """
    if not ranges:
        return None

    # First, try exact range match
    for min_q, max_q, col in ranges:
        if min_q <= qty <= max_q:
            price = to_float(price_row.get(col))
            if price is not None:
                return price

    # For single-number columns (min==max), find the best match
    # Pick the highest single-number column that is <= qty
    single_cols = [(min_q, col) for min_q, max_q, col in ranges if min_q == max_q]
    if single_cols:
        # Sort by quantity descending
        single_cols.sort(key=lambda x: x[0], reverse=True)
        for threshold, col in single_cols:
            if qty >= threshold:
                price = to_float(price_row.get(col))
                if price is not None:
                    return price

    # fallback: qty above last range -> use last available price
    last_min, last_max, last_col = ranges[-1]
    if qty > last_max:
        price = to_float(price_row.get(last_col))
        if price is not None:
            return price

    # qty below first range -> use first available price
    first_min, first_max, first_col = ranges[0]
    if qty < first_min:
        price = to_float(price_row.get(first_col))
        if price is not None:
            return price
    
    # Try to find ANY non-null price in the ranges
    for min_q, max_q, col in ranges:
        price = to_float(price_row.get(col))
        if price is not None:
            return price

    return None


# -------------------------
# Excel reading
# -------------------------
def read_excel_any(path: str) -> pd.DataFrame:
    """
    Read .xls/.xlsx with pandas.
    .xls requires xlrd==2.0.1 installed.
    """
    ext = os.path.splitext(path)[1].lower()
    try:
        if ext == ".xls":
            return pd.read_excel(path, engine="xlrd")
        else:
            return pd.read_excel(path, engine="openpyxl")
    except ImportError as e:
        raise ImportError(
            "–õ–∏–ø—Å–≤–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∑–∞ —á–µ—Ç–µ–Ω–µ. –ò–Ω—Å—Ç–∞–ª–∏—Ä–∞–π:\n"
            "pip install pandas openpyxl xlrd==2.0.1\n\n"
            f"–û—Ä–∏–≥–∏–Ω–∞–ª–Ω–∞ –≥—Ä–µ—à–∫–∞: {e}"
        )
    except Exception as e:
        raise RuntimeError(f"–ù–µ —É—Å–ø—è—Ö –¥–∞ –ø—Ä–æ—á–µ—Ç–∞ —Ñ–∞–π–ª–∞: {path}\n–ì—Ä–µ—à–∫–∞: {e}")


def merge_order_and_prices(order_path: str, prices_path: str) -> pd.DataFrame:
    df_order = read_excel_any(order_path)
    df_prices = read_excel_any(prices_path)

    DEBUG = os.environ.get("MERGE_DEBUG", "0") in ("1", "true", "True")
    if DEBUG:
        print("[DEBUG] Order columns:", list(df_order.columns))
        print("[DEBUG] Prices columns:", list(df_prices.columns))

    # Find order columns
    col_order_no = find_column(df_order, ["–Ω–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞", "–ø–æ—Ä—ä—á–∫–∞", "Purchase Order"])
    col_item = find_column(df_order, ["–∏–º–µ –Ω–∞ –∞—Ä—Ç–∏–∫—É–ª", "–∞—Ä—Ç–∏–∫—É–ª", "–ø—Ä–æ–¥—É–∫—Ç", "Item Number"])
    col_qty = find_column(df_order, ["–∑–∞—è–≤–µ–Ω–∏ –±—Ä–æ–π–∫–∏", "–±—Ä–æ–π–∫–∏", "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ", "Quantity Ordered"])
    col_date = find_column(df_order, ["–¥–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞", "–¥–æ—Å—Ç–∞–≤–∫–∞", "delivery", "Due Date"])

    # Find prices columns
    p_item = find_column(df_prices, ["–∫–æ–¥ –ê–õ —Ñ–∏–ª—Ç—ä—Ä", "–∞—Ä—Ç–∏–∫—É–ª", "item"])

    try:
        p_tl = find_column(df_prices, ["—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ–Ω –ª–∏—Å—Ç", "–¢–õ", "tech"])
    except Exception:
        p_tl = None

    try:
        p_size = find_column(
            df_prices,
            ["—Ä–∞–∑–º–µ—Ä", "—à–∏—Ä./–≤–∏—Å.", "—à–∏—Ä/–≤–∏—Å", "—à–∏—Ä–∏–Ω–∞/–≤–∏—Å–æ—á–∏–Ω–∞", "—à–∏—Ä–∏–Ω–∞/–≤–∏—Å", "size", "width/height"]
        )
    except Exception:
        p_size = None
        # fallback: try to find a header containing both —à–∏—Ä and –≤–∏—Å
        for c in df_prices.columns:
            try:
                h = normalize(c)
                if "—à–∏—Ä" in h and "–≤–∏—Å" in h:
                    p_size = c
                    break
            except Exception:
                continue

    try:
        p_mat = find_column(df_prices, ["–º–∞—Ç–µ—Ä–∏–∞–ª", "material"])
    except Exception:
        p_mat = None

    # Detect range columns like "1 000 - 1 999", "2 000 - 2 999", ...
    range_cols = detect_range_columns(df_prices)
    if not range_cols:
        raise ValueError(
            "–ù–µ –æ—Ç–∫—Ä–∏—Ö —Ü–µ–Ω–æ–≤–∏ –∫–æ–ª–æ–Ω–∏ —Ç–∏–ø –¥–∏–∞–ø–∞–∑–æ–Ω (–Ω–∞–ø—Ä. '1 000 - 1 999'). "
            "–ü—Ä–æ–≤–µ—Ä–∏ –∑–∞–≥–ª–∞–≤–∏—è—Ç–∞ –≤ —Ç–∞–±–ª–∏—Ü–∞ '–¶–µ–Ω–∏'."
        )

    # Build lookup: keep full row so we can read price from range columns
    # Use multiple keys for better matching: original, normalized, and canonical
    # When there are multiple rows for the same article, keep the one with more filled prices
    prices_lookup = {}
    
    def count_filled_prices(row):
        """Count how many price range columns have valid (non-NaN) values."""
        count = 0
        for _, _, col in range_cols:
            val = row.get(col)
            if not pd.isna(val):
                count += 1
        return count
    
    for _, pr in df_prices.iterrows():
        name = pr.get(p_item)
        if pd.isna(name):
            continue
        name = str(name).strip()
        name_norm = normalize(name)
        name_canon = canonical_code(name)
        info = {
            "row": pr,
            "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ–Ω –ª–∏—Å—Ç": "" if p_tl is None or pd.isna(pr.get(p_tl)) else str(pr.get(p_tl)).strip(),
            "–†–∞–∑–º–µ—Ä": "" if p_size is None or pd.isna(pr.get(p_size)) else str(pr.get(p_size)).strip(),
            "–ú–∞—Ç–µ—Ä–∏–∞–ª": "" if p_mat is None or pd.isna(pr.get(p_mat)) else str(pr.get(p_mat)).strip(),
        }
        
        # Only update if this is a new key or if this row has more filled price columns
        new_count = count_filled_prices(pr)
        for key in [name, name_norm, name_canon]:
            if key is None:
                continue
            existing = prices_lookup.get(key)
            if existing is None:
                prices_lookup[key] = info
            else:
                # Compare: keep the row with more filled prices
                old_count = count_filled_prices(existing["row"])
                if new_count > old_count:
                    prices_lookup[key] = info

    if DEBUG:
        print(f"[DEBUG] Built prices_lookup with {len(prices_lookup)} keys. Sample keys: {list(prices_lookup.keys())[:6]}")

    # Merge
    out_rows = []
    line_no = 0

    for _, r in df_order.iterrows():
        order_no = r.get(col_order_no)
        item = r.get(col_item)
        qty = r.get(col_qty)
        ddate = r.get(col_date)

        if pd.isna(order_no) or pd.isna(item):
            continue

        order_no = str(order_no).strip()
        item = str(item).strip()
        item_norm = normalize(item)
        item_canon = canonical_code(item)

        qty_i = to_int(qty)
        if qty_i is None:
            continue

        line_no += 1
        order_ref = f"{order_no}-{line_no}"

        # find price row - STRICT matching by canonical code only
        # (–∞—Ä—Ç–∏–∫—É–ª–Ω–∏—è—Ç –Ω–æ–º–µ—Ä –æ—Ç –ø–æ—Ä—ä—á–∫–∞—Ç–∞ —Ç—Ä—è–±–≤–∞ –¥–∞ —Å—ä–≤–ø–∞–¥–∞ —Ç–æ—á–Ω–æ —Å "–∫–æ–¥ –ê–õ —Ñ–∏–ª—Ç—ä—Ä")
        price_info = None
        exact_match = False
        
        # Try exact canonical code match first
        if item_canon and item_canon in prices_lookup:
            price_info = prices_lookup.get(item_canon)
            exact_match = True
            if DEBUG:
                print(f"[DEBUG] Exact canonical match: '{item}' (canon='{item_canon}')")
        
        # Try exact normalized match
        if not exact_match and item_norm in prices_lookup:
            price_info = prices_lookup.get(item_norm)
            exact_match = True
            if DEBUG:
                print(f"[DEBUG] Exact normalized match: '{item}' (norm='{item_norm}')")
        
        # Try exact original match
        if not exact_match and item in prices_lookup:
            price_info = prices_lookup.get(item)
            exact_match = True
            if DEBUG:
                print(f"[DEBUG] Exact original match: '{item}'")
        
        # Try partial code match: if order item contains the price code or vice versa
        if not exact_match:
            for price_key, price_val in prices_lookup.items():
                if not isinstance(price_key, str) or not price_key:
                    continue
                price_canon = canonical_code(price_key)
                # Check if item code contains price code or price code contains item code
                if price_canon and item_canon:
                    if price_canon in item_canon or item_canon in price_canon:
                        price_info = price_val
                        exact_match = True
                        if DEBUG:
                            print(f"[DEBUG] Partial code match: '{item}' (canon='{item_canon}') contains/in '{price_key}' (canon='{price_canon}')")
                        break
        
        if not exact_match and DEBUG:
            print(f"[DEBUG] No exact match for '{item}' (canon='{item_canon}') - –ï–¥. –¶–µ–Ω–∞ and –°—É–º–∞ will be empty")

        unit_price = None
        size = ""
        tl = ""
        mat = ""

        if price_info and exact_match:
            unit_price = resolve_unit_price_from_ranges(qty_i, price_info["row"], range_cols)
            size = price_info.get("–†–∞–∑–º–µ—Ä", "") or ""
            tl = price_info.get("–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ–Ω –ª–∏—Å—Ç", "") or ""
            mat = price_info.get("–ú–∞—Ç–µ—Ä–∏–∞–ª", "") or ""
            if DEBUG and unit_price is None:
                # show raw values in each range column for troubleshooting
                raw_vals = [(c, price_info["row"].get(c)) for _, _, c in range_cols]
                print(f"[DEBUG] Item '{item}' matched but unit_price=None. qty={qty_i}. Raw range values: {raw_vals[:6]}...")
        else:
            # No exact match - leave price fields empty
            if DEBUG:
                print(f"[DEBUG] Item '{item}' - no exact match, –ï–¥. –¶–µ–Ω–∞ and –°—É–º–∞ will be empty.")

        total = round(unit_price * qty_i, 2) if unit_price is not None else None

        out_rows.append({
            "–ê—Ä—Ç–∏–∫—É–ª": item,
            "–†–∞–∑–º–µ—Ä": size,
            "–ë—Ä–æ–π–∫–∏": qty_i,
            "–ï–¥. –¶–µ–Ω–∞": "" if unit_price is None else unit_price,
            "–°—É–º–∞": "" if total is None else total,
            "–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥": order_ref,
            "–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞": excel_cell_to_string(ddate),  # keep as string
            "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ–Ω –ª–∏—Å—Ç": tl,
            "–ú–∞—Ç–µ—Ä–∏–∞–ª": mat,
        })

    return pd.DataFrame(out_rows)


def _apply_date_format_xlsx(path: Path, header_name: str = "–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞"):
    """
    Post-process an .xlsx file to ensure the column with header_name contains real datetimes
    and has a sensible Excel number format.
    NOTE: You wanted date as string, so this is typically NOT needed for your generated orders.
    It's kept only because your protocol logic uses it.
    """
    if load_workbook is None:
        return
    try:
        wb = load_workbook(filename=str(path))
        ws = wb.active
        header_col = None
        for cell in ws[1]:
            try:
                if str(cell.value).strip() == header_name:
                    header_col = cell.column
                    break
            except Exception:
                continue
        if header_col is None:
            wb.close()
            return

        for row in ws.iter_rows(min_row=2, min_col=header_col, max_col=header_col):
            cell = row[0]
            val = cell.value
            if val is None:
                continue
            import datetime as _dt
            if isinstance(val, (_dt.datetime, _dt.date)):
                cell.number_format = 'yyyy-mm-dd'
                continue

            try:
                parsed = pd.to_datetime(val, dayfirst=True, errors='coerce')
            except Exception:
                parsed = pd.to_datetime(val, errors='coerce')
            if pd.isna(parsed):
                continue
            try:
                cell.value = parsed.to_pydatetime()
            except Exception:
                continue
            cell.number_format = 'yyyy-mm-dd'

        wb.save(filename=str(path))
        wb.close()
    except Exception:
        try:
            wb.close()
        except Exception:
            pass


def load_settings():
    try:
        if SETTINGS_FILE.exists():
            with open(SETTINGS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    return {}


def save_settings(s: dict):
    try:
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        with open(SETTINGS_FILE, "w", encoding="utf-8") as f:
            json.dump(s, f, ensure_ascii=False, indent=2)
    except Exception:
        pass


def set_protocols_dir(path_str: str):
    """Set protocols directory (no persistence - user must choose each session)."""
    global PROTOCOLS_DIR
    try:
        p = Path(path_str).expanduser().resolve()
    except Exception:
        p = Path(path_str)
    p.mkdir(parents=True, exist_ok=True)
    PROTOCOLS_DIR = p


def ensure_dirs():
    """–°—ä–∑–¥–∞–≤–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏—Ç–µ –∑–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∏ –∞–∫–æ —Å–∞ –∏–∑–±—Ä–∞–Ω–∏."""
    if PROTOCOLS_DIR is not None:
        try:
            PROTOCOLS_DIR.mkdir(parents=True, exist_ok=True)
        except Exception:
            pass


def week_key_from_date(d):
    if pd.isna(d) or d == "":
        return "protocol_undated"
    if isinstance(d, str):
        s = d.strip()
        # Try ISO format first (YYYY-MM-DD) - must not use dayfirst for this
        if re.match(r"^\d{4}-\d{2}-\d{2}", s):
            dt = pd.to_datetime(s, errors="coerce")
        else:
            # For other formats like DD-MM-YYYY, DD/MM/YYYY, DD.MM.YYYY use dayfirst
            try:
                dt = pd.to_datetime(s, dayfirst=True, errors="coerce")
            except Exception:
                dt = pd.to_datetime(s, errors="coerce")
    else:
        dt = pd.to_datetime(d, errors="coerce")

    if pd.isna(dt):
        return "protocol_undated"
    iso = dt.isocalendar()
    return f"protocol_{iso.year}_w{iso.week}"


def append_to_protocol(protocol_key: str, df_rows: pd.DataFrame, source_filename: str):
    ensure_dirs()
    prot_xlsx = PROTOCOLS_DIR / f"{protocol_key}.xlsx"
    
    # Check if protocol is closed (read-only or _CLOSED in name)
    if "_CLOSED" in protocol_key or is_file_readonly(prot_xlsx):
        raise RuntimeError(f"–ü—Ä–æ—Ç–æ–∫–æ–ª {protocol_key} –µ –ø—Ä–∏–∫–ª—é—á–µ–Ω. –ù–æ–≤–∏ —Ä–µ–¥–æ–≤–µ –Ω–µ –º–æ–≥–∞—Ç –¥–∞ —Å–µ –¥–æ–±–∞–≤—è—Ç.")

    cols = ["–ê—Ä—Ç–∏–∫—É–ª", "–†–∞–∑–º–µ—Ä", "–ë—Ä–æ–π–∫–∏", "–ï–¥. –¶–µ–Ω–∞", "–°—É–º–∞", "–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥", "–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞", "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ–Ω –ª–∏—Å—Ç", "–ú–∞—Ç–µ—Ä–∏–∞–ª"]
    out = df_rows.copy()
    for c in cols:
        if c not in out.columns:
            out[c] = ""
    out = out[cols]

    if prot_xlsx.exists():
        try:
            existing = pd.read_excel(prot_xlsx, engine="openpyxl")
            
            # Remove duplicates: if "–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥" already exists, replace with new data
            if "–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥" in existing.columns and "–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥" in out.columns:
                # Get the order refs from new data
                new_refs = set(out["–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥"].dropna().astype(str).tolist())
                # Keep only rows from existing that are NOT in new data
                existing_filtered = existing[~existing["–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥"].astype(str).isin(new_refs)]
                new_all = pd.concat([existing_filtered, out], ignore_index=True)
            else:
                new_all = pd.concat([existing, out], ignore_index=True)
        except Exception:
            new_all = out
    else:
        new_all = out

    # If you really want protocols to have real date cells, keep this.
    if "–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞" in new_all.columns:
        try:
            new_all["–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞"] = pd.to_datetime(new_all["–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞"], errors="coerce")
        except Exception:
            pass

    new_all.to_excel(prot_xlsx, index=False)
    try:
        _apply_date_format_xlsx(prot_xlsx, header_name="–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞")
    except Exception:
        pass


# -------------------------
# Tkinter UI
# -------------------------
class App(tk.Tk):
    def __init__(self):
        super().__init__()
        self.title("–°–ª–∏–≤–∞–Ω–µ –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ + —Ü–µ–Ω–∏ (Excel)")
        self.geometry("1200x650")

        self.order_path = tk.StringVar(value="")
        self.prices_path = tk.StringVar(value="")
        self.protocols_dir_var = tk.StringVar(value="(–Ω–µ –µ –∏–∑–±—Ä–∞–Ω–∞)")

        self.df_merged = None
        self._rendered_index_map = []
        self._current_file_path = None  # Path to currently loaded file for saving

        self._build_ui()

    def _build_ui(self):
        top = ttk.Frame(self, padding=10)
        top.pack(side=tk.TOP, fill=tk.X)

        btn_order = ttk.Button(top, text="–ö–∞—á–∏ –ü–æ—Ä—ä—á–∫–∞ (.xls/.xlsx)", command=self.pick_order)
        btn_prices = ttk.Button(top, text="–ö–∞—á–∏ –¶–µ–Ω–∏ (.xls/.xlsx)", command=self.pick_prices)
        btn_merge = ttk.Button(top, text="–°–ª–µ–π", command=self.do_merge)
        btn_save = ttk.Button(top, text="–ó–∞–ø–∞–∑–∏ –∫–∞—Ç–æ...", command=self.save_xlsx)

        self.search_var = tk.StringVar(value="")
        self.search_entry = ttk.Entry(top, textvariable=self.search_var, width=30)
        btn_search = ttk.Button(top, text="–¢—ä—Ä—Å–∏", command=self.on_search)

        # Row 1 buttons - single order processing
        btn_order.grid(row=0, column=0, padx=5, pady=5, sticky="w")
        btn_prices.grid(row=0, column=1, padx=5, pady=5, sticky="w")
        btn_merge.grid(row=0, column=2, padx=5, pady=5, sticky="w")
        btn_save.grid(row=0, column=3, padx=5, pady=5, sticky="w")
        self.search_entry.grid(row=0, column=4, padx=5, pady=5, sticky="w")
        btn_search.grid(row=0, column=5, padx=5, pady=5, sticky="w")

        # Row 2 - protocol management buttons
        btn_choose_protocols = ttk.Button(top, text="–ò–∑–±–µ—Ä–∏ –ø–∞–ø–∫–∞ –∑–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∏", command=self.choose_protocols_folder)
        btn_batch = ttk.Button(top, text="–ö–∞—á–∏ –º–Ω–æ–≥–æ –ø–æ—Ä—ä—á–∫–∏", command=self.batch_process)
        btn_view_protocols = ttk.Button(top, text="–ü—Ä–µ–≥–ª–µ–¥ –ø—Ä–æ—Ç–æ–∫–æ–ª–∏", command=self.view_protocols)
        btn_close_protocol = ttk.Button(top, text="–ü—Ä–∏–∫–ª—é—á–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª", command=self.close_protocol)
        btn_reopen_protocol = ttk.Button(top, text="–û—Ç–≤–æ—Ä–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª", command=self.reopen_protocol)
        
        btn_choose_protocols.grid(row=1, column=0, padx=5, pady=2, sticky="w")
        btn_batch.grid(row=1, column=1, padx=5, pady=2, sticky="w")
        btn_view_protocols.grid(row=1, column=2, padx=5, pady=2, sticky="w")
        btn_close_protocol.grid(row=1, column=3, padx=5, pady=2, sticky="w")
        btn_reopen_protocol.grid(row=1, column=4, padx=5, pady=2, sticky="w")

        ttk.Label(top, text="–ü–æ—Ä—ä—á–∫–∞:").grid(row=2, column=0, sticky="w")
        ttk.Label(top, textvariable=self.order_path).grid(row=2, column=1, columnspan=6, sticky="w")

        ttk.Label(top, text="–¶–µ–Ω–∏:").grid(row=3, column=0, sticky="w")
        ttk.Label(top, textvariable=self.prices_path).grid(row=3, column=1, columnspan=6, sticky="w")

        ttk.Label(top, text="–ü—Ä–æ—Ç–æ–∫–æ–ª–∏: ").grid(row=4, column=0, sticky="w")
        ttk.Label(top, textvariable=self.protocols_dir_var).grid(row=4, column=1, columnspan=6, sticky="w")

        mid = ttk.Frame(self, padding=(10, 0, 10, 10))
        mid.pack(side=tk.TOP, fill=tk.BOTH, expand=True)

        self.tree = ttk.Treeview(mid, show="headings")
        vsb = ttk.Scrollbar(mid, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(mid, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscroll=vsb.set, xscroll=hsb.set)

        self.tree.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        vsb.pack(side=tk.RIGHT, fill=tk.Y)
        hsb.pack(side=tk.BOTTOM, fill=tk.X)

        self.tree.bind("<Double-1>", self.on_row_double_click)

        # Bottom bar with status
        self.status = tk.StringVar(value="–ò–∑–±–µ—Ä–∏ –¥–≤–∞—Ç–∞ —Ñ–∞–π–ª–∞ –∏ –Ω–∞—Ç–∏—Å–Ω–∏ '–°–ª–µ–π'.")
        ttk.Label(self, textvariable=self.status, padding=10).pack(side=tk.BOTTOM, fill=tk.X)

    def pick_order(self):
        path = filedialog.askopenfilename(
            title="–ò–∑–±–µ—Ä–∏ —Ñ–∞–π–ª –ü–æ—Ä—ä—á–∫–∞",
            filetypes=[("Excel", "*.xlsx"), ("Excel 97-2003", "*.xls"), ("All files", "*.*")]
        )
        if path:
            self.order_path.set(path)

    def pick_prices(self):
        path = filedialog.askopenfilename(
            title="–ò–∑–±–µ—Ä–∏ —Ñ–∞–π–ª –¶–µ–Ω–∏",
            filetypes=[("Excel", "*.xlsx"), ("Excel 97-2003", "*.xls"), ("All files", "*.*")]
        )
        if path:
            self.prices_path.set(path)

    def choose_protocols_folder(self):
        path = filedialog.askdirectory(title="–ò–∑–±–µ—Ä–∏ –ø–∞–ø–∫–∞ –∑–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∏")
        if not path:
            return
        try:
            set_protocols_dir(path)
            self.protocols_dir_var.set(str(PROTOCOLS_DIR))
            self.status.set(f"–ü–∞–ø–∫–∞ –∑–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∏: {PROTOCOLS_DIR}")
        except Exception as e:
            messagebox.showerror("–ì—Ä–µ—à–∫–∞", f"–ù–µ –º–æ–≥–∞ –¥–∞ –∑–∞–¥–∞–º –ø–∞–ø–∫–∞—Ç–∞: {e}")

    def view_protocols(self):
        """Show list of all protocols with their status."""
        if self.protocols_dir_var.get() == "(–Ω–µ –µ –∏–∑–±—Ä–∞–Ω–∞)":
            messagebox.showwarning("–ü—Ä–æ—Ç–æ–∫–æ–ª–∏", "–ü—ä—Ä–≤–æ –∏–∑–±–µ—Ä–∏ –ø–∞–ø–∫–∞ –∑–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∏.")
            return
        
        protocols = []
        for p in PROTOCOLS_DIR.glob("protocol_*.xlsx"):
            name = p.stem
            # Check if closed by name (_CLOSED suffix)
            if "_CLOSED" in name:
                status = "–ü–†–ò–ö–õ–Æ–ß–ï–ù"
                display_name = name.replace("_CLOSED", "")
            else:
                status = "–û—Ç–≤–æ—Ä–µ–Ω"
                display_name = name
            try:
                df = pd.read_excel(p, engine="openpyxl")
                rows = len(df)
            except Exception:
                rows = "?"
            protocols.append((display_name, status, rows, name))
        
        if not protocols:
            messagebox.showinfo("–ü—Ä–æ—Ç–æ–∫–æ–ª–∏", "–ù—è–º–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∏ –≤ –∏–∑–±—Ä–∞–Ω–∞—Ç–∞ –ø–∞–ø–∫–∞.")
            return
        
        # Create popup window
        popup = tk.Toplevel(self)
        popup.title("–ü—Ä–æ—Ç–æ–∫–æ–ª–∏")
        popup.geometry("600x400")
        
        tree = ttk.Treeview(popup, columns=("–ò–º–µ", "–°—Ç–∞—Ç—É—Å", "–†–µ–¥–æ–≤–µ"), show="headings")
        tree.heading("–ò–º–µ", text="–ü—Ä–æ—Ç–æ–∫–æ–ª")
        tree.heading("–°—Ç–∞—Ç—É—Å", text="–°—Ç–∞—Ç—É—Å")
        tree.heading("–†–µ–¥–æ–≤–µ", text="–†–µ–¥–æ–≤–µ")
        tree.column("–ò–º–µ", width=300)
        tree.column("–°—Ç–∞—Ç—É—Å", width=120)
        tree.column("–†–µ–¥–æ–≤–µ", width=80)
        
        for display_name, status, rows, full_name in sorted(protocols, reverse=True):
            tree.insert("", "end", values=(display_name, status, rows), tags=(full_name,))
        
        tree.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        def open_selected():
            sel = tree.selection()
            if not sel:
                return
            # Get full name from tags
            full_name = tree.item(sel[0])["tags"][0]
            prot_path = PROTOCOLS_DIR / f"{full_name}.xlsx"
            if prot_path.exists():
                try:
                    df = pd.read_excel(prot_path, engine="openpyxl")
                    self.df_merged = df
                    self._current_file_path = str(prot_path)  # Remember path for saving
                    self._load_table(df)
                    self.status.set(f"–ó–∞—Ä–µ–¥–µ–Ω–∏ {len(df)} —Ä–µ–¥–∞ –æ—Ç {full_name} (–¥–≤–æ–µ–Ω –∫–ª–∏–∫ –∑–∞ —Ä–µ–¥–∞–∫—Ü–∏—è)")
                    popup.destroy()
                except Exception as e:
                    messagebox.showerror("–ì—Ä–µ—à–∫–∞", f"–ù–µ –º–æ–≥–∞ –¥–∞ –æ—Ç–≤–æ—Ä—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞: {e}")
        
        btn_open = ttk.Button(popup, text="–û—Ç–≤–æ—Ä–∏ –≤ —Ç–∞–±–ª–∏—Ü–∞—Ç–∞", command=open_selected)
        btn_open.pack(pady=5)

    def close_protocol(self):
        """Mark a protocol as closed (no more rows can be added)."""
        if self.protocols_dir_var.get() == "(–Ω–µ –µ –∏–∑–±—Ä–∞–Ω–∞)":
            messagebox.showwarning("–ü—Ä–æ—Ç–æ–∫–æ–ª–∏", "–ü—ä—Ä–≤–æ –∏–∑–±–µ—Ä–∏ –ø–∞–ø–∫–∞ –∑–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∏.")
            return
        
        # Find protocols without _CLOSED in name
        open_protocols = [p.stem for p in PROTOCOLS_DIR.glob("protocol_*.xlsx") 
                          if "_CLOSED" not in p.stem]
        
        if not open_protocols:
            messagebox.showinfo("–ü—Ä–æ—Ç–æ–∫–æ–ª–∏", "–ù—è–º–∞ –æ—Ç–≤–æ—Ä–µ–Ω–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∏ –∑–∞ –ø—Ä–∏–∫–ª—é—á–≤–∞–Ω–µ.")
            return
        
        # Create selection dialog
        popup = tk.Toplevel(self)
        popup.title("–ü—Ä–∏–∫–ª—é—á–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª")
        popup.geometry("400x300")
        
        ttk.Label(popup, text="–ò–∑–±–µ—Ä–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª –∑–∞ –ø—Ä–∏–∫–ª—é—á–≤–∞–Ω–µ:").pack(pady=10)
        
        listbox = tk.Listbox(popup, selectmode=tk.SINGLE, width=50, height=10)
        for p in sorted(open_protocols, reverse=True):
            listbox.insert(tk.END, p)
        listbox.pack(padx=10, pady=5, fill=tk.BOTH, expand=True)
        
        def do_close():
            sel = listbox.curselection()
            if not sel:
                messagebox.showwarning("–ò–∑–±–æ—Ä", "–ò–∑–±–µ—Ä–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª –æ—Ç —Å–ø–∏—Å—ä–∫–∞.")
                return
            name = listbox.get(sel[0])
            
            if messagebox.askyesno("–ü–æ—Ç–≤—ä—Ä–∂–¥–µ–Ω–∏–µ", 
                f"–°–∏–≥—É—Ä–µ–Ω –ª–∏ —Å–∏, —á–µ –∏—Å–∫–∞—à –¥–∞ –ø—Ä–∏–∫–ª—é—á–∏—à –ø—Ä–æ—Ç–æ–∫–æ–ª '{name}'?\n\n"
                "–°–ª–µ–¥ –ø—Ä–∏–∫–ª—é—á–≤–∞–Ω–µ –Ω—è–º–∞ –¥–∞ –º–æ–∂–µ—à –¥–∞ –¥–æ–±–∞–≤—è—à –Ω–æ–≤–∏ —Ä–µ–¥–æ–≤–µ –∫—ä–º –Ω–µ–≥–æ.\n"
                "–§–∞–π–ª—ä—Ç —â–µ –±—ä–¥–µ –ø—Ä–µ–∏–º–µ–Ω—É–≤–∞–Ω —Å _CLOSED –∏ –∑–∞—â–∏—Ç–µ–Ω –æ—Ç –ø—Ä–æ–º–µ–Ω–∏."):
                
                prot_file = PROTOCOLS_DIR / f"{name}.xlsx"
                closed_file = PROTOCOLS_DIR / f"{name}_CLOSED.xlsx"
                
                if prot_file.exists():
                    # Rename to _CLOSED
                    try:
                        prot_file.rename(closed_file)
                        # Set file as read-only
                        set_file_readonly(closed_file, readonly=True)
                        messagebox.showinfo("–ì–æ—Ç–æ–≤–æ", f"–ü—Ä–æ—Ç–æ–∫–æ–ª '{name}' –µ –ø—Ä–∏–∫–ª—é—á–µ–Ω.\n–ù–æ–≤–æ –∏–º–µ: {closed_file.name}")
                    except Exception as e:
                        messagebox.showerror("–ì—Ä–µ—à–∫–∞", f"–ù–µ –º–æ–≥–∞ –¥–∞ –ø—Ä–µ–∏–º–µ–Ω—É–≤–∞–º —Ñ–∞–π–ª–∞: {e}")
                        return
                
                popup.destroy()
        
        ttk.Button(popup, text="–ü—Ä–∏–∫–ª—é—á–∏", command=do_close).pack(pady=10)

    def reopen_protocol(self):
        """Reopen a closed protocol."""
        if self.protocols_dir_var.get() == "(–Ω–µ –µ –∏–∑–±—Ä–∞–Ω–∞)":
            messagebox.showwarning("–ü—Ä–æ—Ç–æ–∫–æ–ª–∏", "–ü—ä—Ä–≤–æ –∏–∑–±–µ—Ä–∏ –ø–∞–ø–∫–∞ –∑–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∏.")
            return
        
        # Find protocols with _CLOSED in name
        closed_protocols = [p.stem for p in PROTOCOLS_DIR.glob("protocol_*_CLOSED.xlsx")]
        
        if not closed_protocols:
            messagebox.showinfo("–ü—Ä–æ—Ç–æ–∫–æ–ª–∏", "–ù—è–º–∞ –ø—Ä–∏–∫–ª—é—á–µ–Ω–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–∏ –∑–∞ –æ—Ç–≤–∞—Ä—è–Ω–µ.")
            return
        
        # Create selection dialog
        popup = tk.Toplevel(self)
        popup.title("–û—Ç–≤–æ—Ä–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª")
        popup.geometry("400x300")
        
        ttk.Label(popup, text="–ò–∑–±–µ—Ä–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª –∑–∞ –æ—Ç–≤–∞—Ä—è–Ω–µ:").pack(pady=10)
        
        listbox = tk.Listbox(popup, selectmode=tk.SINGLE, width=50, height=10)
        for p in sorted(closed_protocols, reverse=True):
            listbox.insert(tk.END, p)
        listbox.pack(padx=10, pady=5, fill=tk.BOTH, expand=True)
        
        def do_reopen():
            sel = listbox.curselection()
            if not sel:
                messagebox.showwarning("–ò–∑–±–æ—Ä", "–ò–∑–±–µ—Ä–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª –æ—Ç —Å–ø–∏—Å—ä–∫–∞.")
                return
            name = listbox.get(sel[0])  # e.g. protocol_2026_w7_CLOSED
            
            closed_file = PROTOCOLS_DIR / f"{name}.xlsx"
            # Remove _CLOSED from name
            open_name = name.replace("_CLOSED", "")
            open_file = PROTOCOLS_DIR / f"{open_name}.xlsx"
            
            if closed_file.exists():
                try:
                    # Remove read-only flag first
                    set_file_readonly(closed_file, readonly=False)
                    # Rename back
                    closed_file.rename(open_file)
                    messagebox.showinfo("–ì–æ—Ç–æ–≤–æ", f"–ü—Ä–æ—Ç–æ–∫–æ–ª '{open_name}' –µ –æ—Ç–≤–æ—Ä–µ–Ω –∑–∞ –¥–æ–±–∞–≤—è–Ω–µ –Ω–∞ —Ä–µ–¥–æ–≤–µ.")
                except Exception as e:
                    messagebox.showerror("–ì—Ä–µ—à–∫–∞", f"–ù–µ –º–æ–≥–∞ –¥–∞ –ø—Ä–µ–∏–º–µ–Ω—É–≤–∞–º —Ñ–∞–π–ª–∞: {e}")
                    return
            
            popup.destroy()
        
        ttk.Button(popup, text="–û—Ç–≤–æ—Ä–∏", command=do_reopen).pack(pady=10)

    def batch_process(self):
        """Process multiple order files at once and add them to weekly protocols."""
        if self.protocols_dir_var.get() == "(–Ω–µ –µ –∏–∑–±—Ä–∞–Ω–∞)" or PROTOCOLS_DIR is None:
            messagebox.showwarning("–ü–∞–ø–∫–∞ –∑–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∏", "–ü—ä—Ä–≤–æ –∏–∑–±–µ—Ä–∏ –ø–∞–ø–∫–∞ –∑–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∏.")
            return
        
        # Create window
        popup = tk.Toplevel(self)
        popup.title("–ö–∞—á–∏ –º–Ω–æ–≥–æ –ø–æ—Ä—ä—á–∫–∏")
        popup.geometry("600x500")
        popup.transient(self)
        
        order_files = []
        
        # Title
        ttk.Label(popup, text="–ö–∞—á–∏ –ø–æ—Ä—ä—á–∫–∏ –∫—ä–º –ø—Ä–æ—Ç–æ–∫–æ–ª–∏", font=("", 14, "bold")).pack(pady=(15, 10))
        
        # Add files button - PROMINENT at top
        def add_files_dialog():
            paths = filedialog.askopenfilenames(
                title="–ò–∑–±–µ—Ä–∏ –ø–æ—Ä—ä—á–∫–∏",
                filetypes=[("Excel", "*.xlsx"), ("Excel 97-2003", "*.xls"), ("All files", "*.*")]
            )
            if paths:
                for p in paths:
                    p_str = str(p).strip()
                    if p_str.lower().endswith(('.xls', '.xlsx')) and p_str not in order_files:
                        order_files.append(p_str)
                        files_listbox.insert(tk.END, Path(p_str).name)
                update_label()
        
        add_btn = ttk.Button(popup, text="üìÇ –î–æ–±–∞–≤–∏ —Ñ–∞–π–ª–æ–≤–µ...", command=add_files_dialog)
        add_btn.pack(pady=10)
        
        # Files list label
        ttk.Label(popup, text="–î–æ–±–∞–≤–µ–Ω–∏ –ø–æ—Ä—ä—á–∫–∏:").pack(anchor="w", padx=20)
        
        # Listbox for files
        list_frame = ttk.Frame(popup)
        list_frame.pack(fill=tk.BOTH, expand=True, padx=20, pady=5)
        
        files_listbox = tk.Listbox(list_frame, selectmode=tk.EXTENDED, height=12)
        files_scrollbar = ttk.Scrollbar(list_frame, orient=tk.VERTICAL, command=files_listbox.yview)
        files_listbox.configure(yscrollcommand=files_scrollbar.set)
        
        files_listbox.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
        files_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
        
        # Status label
        status_label = ttk.Label(popup, text="–ù—è–º–∞ –¥–æ–±–∞–≤–µ–Ω–∏ —Ñ–∞–π–ª–æ–≤–µ", foreground="gray")
        status_label.pack(pady=5)
        
        def update_label():
            if order_files:
                status_label.configure(text=f"{len(order_files)} —Ñ–∞–π–ª–∞ –¥–æ–±–∞–≤–µ–Ω–∏", foreground="green")
            else:
                status_label.configure(text="–ù—è–º–∞ –¥–æ–±–∞–≤–µ–Ω–∏ —Ñ–∞–π–ª–æ–≤–µ", foreground="gray")
        
        # Action buttons
        btn_frame = ttk.Frame(popup)
        btn_frame.pack(fill=tk.X, padx=20, pady=5)
        
        def remove_selected():
            selected = list(files_listbox.curselection())
            for i in reversed(selected):
                files_listbox.delete(i)
                del order_files[i]
            update_label()
        
        def clear_all():
            files_listbox.delete(0, tk.END)
            order_files.clear()
            update_label()
        
        ttk.Button(btn_frame, text="–ü—Ä–µ–º–∞—Ö–Ω–∏ –∏–∑–±—Ä–∞–Ω–∏—Ç–µ", command=remove_selected).pack(side=tk.LEFT, padx=5)
        ttk.Button(btn_frame, text="–ò–∑—á–∏—Å—Ç–∏ –≤—Å–∏—á–∫–∏", command=clear_all).pack(side=tk.LEFT, padx=5)
        
        # Separator and bottom buttons
        ttk.Separator(popup, orient=tk.HORIZONTAL).pack(fill=tk.X, padx=20, pady=10)
        
        bottom_frame = ttk.Frame(popup)
        bottom_frame.pack(fill=tk.X, padx=20, pady=10)
        
        def do_process():
            if not order_files:
                messagebox.showwarning("–õ–∏–ø—Å–≤–∞—Ç —Ñ–∞–π–ª–æ–≤–µ", "–î–æ–±–∞–≤–∏ –ø–æ–Ω–µ –µ–¥–Ω–∞ –ø–æ—Ä—ä—á–∫–∞.")
                return
            popup.destroy()
            self._process_batch_files(order_files)
        
        ttk.Button(bottom_frame, text="–û—Ç–∫–∞–∑", command=popup.destroy).pack(side=tk.RIGHT, padx=5)
        ttk.Button(bottom_frame, text="–û–±—Ä–∞–±–æ—Ç–∏", command=do_process).pack(side=tk.RIGHT, padx=5)

    def _process_batch_files(self, order_files):
        """Process the batch of order files (already contain prices)."""
        processed = 0
        errors = []
        all_merged = []
        
        # Expected columns in protocol
        protocol_cols = ["–ê—Ä—Ç–∏–∫—É–ª", "–†–∞–∑–º–µ—Ä", "–ë—Ä–æ–π–∫–∏", "–ï–¥. –¶–µ–Ω–∞", "–°—É–º–∞", 
                         "–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥", "–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞", "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ–Ω –ª–∏—Å—Ç", "–ú–∞—Ç–µ—Ä–∏–∞–ª"]
        
        # Column name mappings (various formats -> standard format)
        col_mappings = {
            # –ê—Ä—Ç–∏–∫—É–ª
            "–∞—Ä—Ç–∏–∫—É–ª": "–ê—Ä—Ç–∏–∫—É–ª",
            "item": "–ê—Ä—Ç–∏–∫—É–ª",
            "item number": "–ê—Ä—Ç–∏–∫—É–ª",
            "–∏–º–µ –Ω–∞ –∞—Ä—Ç–∏–∫—É–ª": "–ê—Ä—Ç–∏–∫—É–ª",
            "–ø—Ä–æ–¥—É–∫—Ç": "–ê—Ä—Ç–∏–∫—É–ª",
            # –†–∞–∑–º–µ—Ä
            "—Ä–∞–∑–º–µ—Ä": "–†–∞–∑–º–µ—Ä",
            "size": "–†–∞–∑–º–µ—Ä",
            # –ë—Ä–æ–π–∫–∏
            "–±—Ä–æ–π–∫–∏": "–ë—Ä–æ–π–∫–∏",
            "–±—Ä–æ–π": "–ë—Ä–æ–π–∫–∏",
            "qty": "–ë—Ä–æ–π–∫–∏",
            "quantity": "–ë—Ä–æ–π–∫–∏",
            "–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ": "–ë—Ä–æ–π–∫–∏",
            # –ï–¥. –¶–µ–Ω–∞
            "–µ–¥. —Ü–µ–Ω–∞": "–ï–¥. –¶–µ–Ω–∞",
            "–µ–¥ —Ü–µ–Ω–∞": "–ï–¥. –¶–µ–Ω–∞",
            "–µ–¥–∏–Ω–∏—á–Ω–∞ —Ü–µ–Ω–∞": "–ï–¥. –¶–µ–Ω–∞",
            "unit price": "–ï–¥. –¶–µ–Ω–∞",
            "—Ü–µ–Ω–∞": "–ï–¥. –¶–µ–Ω–∞",
            # –°—É–º–∞
            "—Å—É–º–∞": "–°—É–º–∞",
            "total": "–°—É–º–∞",
            "amount": "–°—É–º–∞",
            "–æ–±—â–∞ —Å—É–º–∞": "–°—É–º–∞",
            # –ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥
            "–Ω–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥": "–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥",
            "–Ω–æ–º–µ—Ä –ø–æ—Ä—ä—á–∫–∞": "–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥",
            "–ø–æ—Ä—ä—á–∫–∞": "–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥",
            "order": "–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥",
            "order number": "–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥",
            "purchase order": "–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥",
            # –î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞
            "–¥–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞": "–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞",
            "–¥–∞—Ç–∞ –¥–æ—Å—Ç–∞–≤–∫–∞": "–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞",
            "–¥–∞—Ç–∞": "–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞",
            "delivery date": "–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞",
            "date": "–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞",
            # –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ–Ω –ª–∏—Å—Ç
            "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ–Ω –ª–∏—Å—Ç": "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ–Ω –ª–∏—Å—Ç",
            "—Ç–ª": "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ–Ω –ª–∏—Å—Ç",
            "tech sheet": "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ–Ω –ª–∏—Å—Ç",
            # –ú–∞—Ç–µ—Ä–∏–∞–ª
            "–º–∞—Ç–µ—Ä–∏–∞–ª": "–ú–∞—Ç–µ—Ä–∏–∞–ª",
            "material": "–ú–∞—Ç–µ—Ä–∏–∞–ª",
        }
        
        # Required columns - file must have at least these
        required_cols = ["–ê—Ä—Ç–∏–∫—É–ª", "–ë—Ä–æ–π–∫–∏"]
        
        for order_path in order_files:
            try:
                # Read the order file directly (it already has all data including prices)
                df = read_excel_any(order_path)
                
                if df.empty:
                    errors.append(f"{Path(order_path).name}: –§–∞–π–ª—ä—Ç –µ –ø—Ä–∞–∑–µ–Ω")
                    continue
                
                # Normalize column names
                new_columns = {}
                for col in df.columns:
                    col_lower = str(col).strip().lower()
                    if col_lower in col_mappings:
                        new_columns[col] = col_mappings[col_lower]
                    elif str(col).strip() in protocol_cols:
                        new_columns[col] = str(col).strip()
                
                if new_columns:
                    df = df.rename(columns=new_columns)
                
                # Check if file has required columns
                missing_cols = [col for col in required_cols if col not in df.columns]
                if missing_cols:
                    errors.append(f"{Path(order_path).name}: –õ–∏–ø—Å–≤–∞—Ç –∫–æ–ª–æ–Ω–∏: {', '.join(missing_cols)}")
                    continue
                
                # Get order name from filename
                order_no = Path(order_path).stem
                
                # Ensure all protocol columns exist (add missing optional ones as empty)
                for col in protocol_cols:
                    if col not in df.columns:
                        df[col] = ""
                
                # Group by week and append to protocols
                ensure_dirs()
                groups = {}
                for _, row in df.iterrows():
                    wk = week_key_from_date(row.get("–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞"))
                    groups.setdefault(wk, []).append(row.to_dict())
                
                for wk, rows in groups.items():
                    df_rows = pd.DataFrame(rows)
                    try:
                        append_to_protocol(wk, df_rows, Path(order_path).name)
                    except RuntimeError as e:
                        # Protocol is closed
                        errors.append(f"{order_no}: {e}")
                
                processed += 1
                all_merged.append(df)
                
            except Exception as e:
                errors.append(f"{Path(order_path).name}: {e}")
        
        # Show results
        if all_merged:
            combined = pd.concat(all_merged, ignore_index=True)
            self.df_merged = combined
            self._load_table(combined)
        
        msg = f"–û–±—Ä–∞–±–æ—Ç–µ–Ω–∏ {processed} –æ—Ç {len(order_files)} –ø–æ—Ä—ä—á–∫–∏."
        if errors:
            msg += f"\n\n–ì—Ä–µ—à–∫–∏:\n" + "\n".join(errors[:10])
            if len(errors) > 10:
                msg += f"\n... –∏ –æ—â–µ {len(errors) - 10} –≥—Ä–µ—à–∫–∏"
            messagebox.showwarning("–†–µ–∑—É–ª—Ç–∞—Ç", msg)
        else:
            messagebox.showinfo("–ì–æ—Ç–æ–≤–æ", msg)
        
        self.status.set(msg.split("\n")[0])

    def do_merge(self):
        op = self.order_path.get().strip()
        pp = self.prices_path.get().strip()
        if not op or not pp:
            messagebox.showwarning("–õ–∏–ø—Å–≤–∞—Ç —Ñ–∞–π–ª–æ–≤–µ", "–ú–æ–ª—è –∏–∑–±–µ—Ä–∏ –∏ –¥–≤–∞—Ç–∞ —Ñ–∞–π–ª–∞ (–ü–æ—Ä—ä—á–∫–∞ –∏ –¶–µ–Ω–∏).")
            return

        try:
            self.df_merged = merge_order_and_prices(op, pp)
            self._current_file_path = None  # New merge, no file yet
            self._load_table(self.df_merged)
            self.status.set(f"–ì–æ—Ç–æ–≤–æ: {len(self.df_merged)} —Ä–µ–¥–∞ —Å–ª–µ—Ç–∏.")
        except Exception as e:
            messagebox.showerror("–ì—Ä–µ—à–∫–∞", str(e))
            self.status.set("–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ —Å–ª–∏–≤–∞–Ω–µ.")

    def save_xlsx(self):
        if self.df_merged is None or self.df_merged.empty:
            messagebox.showinfo("–ù—è–º–∞ –¥–∞–Ω–Ω–∏", "–ü—ä—Ä–≤–æ –Ω–∞—Ç–∏—Å–Ω–∏ '–°–ª–µ–π'.")
            return

        default_name = "Porachka.xlsx"
        try:
            first_ref = str(self.df_merged.iloc[0]["–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥"])
            order_no = first_ref.split("-")[0]
            default_name = f"Porachka_{order_no}.xlsx"
        except Exception:
            pass

        out_path = filedialog.asksaveasfilename(
            title="–ó–∞–ø–∞–∑–∏ –∫–∞—Ç–æ",
            defaultextension=".xlsx",
            initialfile=default_name,
            filetypes=[("Excel Workbook", "*.xlsx")]
        )
        if not out_path:
            return

        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–≤–∞–º–µ –¥–∞—Ç–∞—Ç–∞ –≤ —Ä–µ–∞–ª–Ω–∞ –¥–∞—Ç–∞ –∑–∞ Numbers/Excel —Å—ä–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç
            df_to_save = self.df_merged.copy()
            if "–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞" in df_to_save.columns:
                df_to_save["–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞"] = pd.to_datetime(df_to_save["–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞"], errors="coerce")
            
            # –ê–∫–æ —Ñ–∞–π–ª—ä—Ç —Å—ä—â–µ—Å—Ç–≤—É–≤–∞, –ø—Ä–µ–∑–∞–ø–∏—Å–≤–∞–º–µ –¥—É–±–ª–∏—Ä–∞—â–∏—Ç–µ —Å–µ —Ä–µ–¥–æ–≤–µ
            if Path(out_path).exists():
                try:
                    existing = pd.read_excel(out_path, engine="openpyxl")
                    if "–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥" in existing.columns and "–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥" in df_to_save.columns:
                        # Get the order refs from new data
                        new_refs = set(df_to_save["–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥"].dropna().astype(str).tolist())
                        # Keep only rows from existing that are NOT in new data
                        existing_filtered = existing[~existing["–ù–æ–º–µ—Ä –Ω–∞ –ø–æ—Ä—ä—á–∫–∞ –∏ —Ä–µ–¥"].astype(str).isin(new_refs)]
                        df_to_save = pd.concat([existing_filtered, df_to_save], ignore_index=True)
                        # Convert date again after merge
                        if "–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞" in df_to_save.columns:
                            df_to_save["–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞"] = pd.to_datetime(df_to_save["–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞"], errors="coerce")
                except Exception:
                    pass  # If can't read existing, just overwrite
            
            with pd.ExcelWriter(out_path, engine="openpyxl") as writer:
                df_to_save.to_excel(writer, index=False, sheet_name="Porachka")
            
            # –ü—Ä–∏–ª–∞–≥–∞–º–µ —Ñ–æ—Ä–º–∞—Ç –∑–∞ –¥–∞—Ç–∞
            try:
                _apply_date_format_xlsx(out_path, header_name="–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞")
            except Exception:
                pass
            
            messagebox.showinfo("–ó–∞–ø–∏—Å–∞–Ω–æ", f"–§–∞–π–ª—ä—Ç –µ –∑–∞–ø–∏—Å–∞–Ω:\n{out_path}")
            self.status.set(f"–ó–∞–ø–∏—Å–∞–Ω–æ: {out_path}")
        except Exception as e:
            messagebox.showerror("–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å", str(e))
            self.status.set("–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å.")
            return

        # Check if protocols folder is selected - append to weekly protocols
        if self.protocols_dir_var.get() == "(–Ω–µ –µ –∏–∑–±—Ä–∞–Ω–∞)":
            # No protocols folder selected, skip adding to protocols
            return

        # Append to weekly protocols
        try:
            ensure_dirs()
            source_name = Path(out_path).name

            # append each row to its weekly protocol
            groups = {}
            for _, row in self.df_merged.iterrows():
                wk = week_key_from_date(row.get("–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞"))
                groups.setdefault(wk, []).append(row.to_dict())

            for wk, rows in groups.items():
                df_rows = pd.DataFrame(rows)
                try:
                    append_to_protocol(wk, df_rows, source_name)
                except Exception as e:
                    messagebox.showwarning("–ü—Ä–æ—Ç–æ–∫–æ–ª", str(e))

        except Exception as e:
            messagebox.showwarning("–î–æ–±–∞–≤—è–Ω–µ –∫—ä–º –ø—Ä–æ—Ç–æ–∫–æ–ª", f"–ì—Ä–µ—à–∫–∞: {e}")

    def _load_table(self, df: pd.DataFrame):
        for col in self.tree["columns"]:
            self.tree.heading(col, text="")
        self.tree.delete(*self.tree.get_children())

        cols = list(df.columns)
        self.tree["columns"] = cols

        for c in cols:
            self.tree.heading(c, text=c)
            self.tree.column(c, width=140, anchor="w")

        max_rows = 2000
        self._rendered_index_map = []
        idx_counter = 0

        for i, row in df.head(max_rows).iterrows():
            values = []
            for c in cols:
                v = row.get(c, "")
                try:
                    if pd.isna(v):
                        values.append("")
                        continue
                except Exception:
                    pass
                values.append(str(v))
            iid = str(idx_counter)
            self.tree.insert("", "end", iid=iid, values=values)
            self._rendered_index_map.append(i)
            idx_counter += 1

        if len(df) > max_rows:
            self.status.set(f"–ü–æ–∫–∞–∑–≤–∞–º –ø—ä—Ä–≤–∏—Ç–µ {max_rows} —Ä–µ–¥–∞ –æ—Ç {len(df)} (–≤—Å–∏—á–∫–∏ —Å–µ –∑–∞–ø–∏—Å–≤–∞—Ç –ø—Ä–∏ export).")

    def on_search(self):
        q = (self.search_var.get() or "").strip()
        if not q:
            messagebox.showinfo("–¢—ä—Ä—Å–µ–Ω–µ", "–í—ä–≤–µ–¥–∏ —Ç–µ–∫—Å—Ç –∑–∞ —Ç—ä—Ä—Å–µ–Ω–µ (–∏–º–µ, –¢–õ –∏–ª–∏ —Ä–∞–∑–º–µ—Ä).")
            return
        ql = q.lower()

        def match_row(r):
            for c in ["–ê—Ä—Ç–∏–∫—É–ª", "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ–Ω –ª–∏—Å—Ç", "–†–∞–∑–º–µ—Ä"]:
                try:
                    v = str(r.get(c, "") or "").lower()
                except Exception:
                    v = ""
                if ql in v:
                    return True
            return False

        if getattr(self, 'df_merged', None) is not None and not self.df_merged.empty:
            try:
                filtered = self.df_merged[self.df_merged.apply(match_row, axis=1)]
                if not filtered.empty:
                    self.df_merged = filtered
                    self._load_table(self.df_merged)
                    self.status.set(f"–ù–∞–º–µ—Ä–µ–Ω–∏ {len(filtered)} —Ä–µ–¥–∞ –∑–∞ '{q}' (–≤ —Ç–µ–∫—É—â–æ—Ç–æ —Å–ª–∏–≤–∞–Ω–µ).")
                    return
            except Exception:
                pass

        # No local orders directory - just search in current merge
        messagebox.showinfo("–¢—ä—Ä—Å–µ–Ω–µ", "–ù—è–º–∞ —Ç–µ–∫—É—â–æ —Å–ª–∏–≤–∞–Ω–µ –∑–∞ —Ç—ä—Ä—Å–µ–Ω–µ. –ü—ä—Ä–≤–æ –∑–∞—Ä–µ–¥–µ—Ç–µ –ø–æ—Ä—ä—á–∫–∞.")

    def on_row_double_click(self, event):
        sel = self.tree.selection()
        if not sel:
            return
        iid = sel[0]
        try:
            idx = int(iid)
        except Exception:
            return
        if idx >= len(self._rendered_index_map):
            return
        df_index = self._rendered_index_map[idx]

        columns = list(self.tree['columns'])
        cur_values = [self.df_merged.at[df_index, c] if c in self.df_merged.columns else '' for c in columns]

        edit = tk.Toplevel(self)
        edit.title("–†–µ–¥–∞–∫—Ü–∏—è –Ω–∞ —Ä–µ–¥")

        entries = {}
        for i, c in enumerate(columns):
            ttk.Label(edit, text=c).grid(row=i, column=0, sticky='w', padx=4, pady=2)
            # Handle NaN/None values - show empty string instead of "nan"
            val = cur_values[i]
            if val is None or (isinstance(val, float) and pd.isna(val)):
                display_val = ""
            else:
                try:
                    if pd.isna(val):
                        display_val = ""
                    else:
                        display_val = str(val)
                except Exception:
                    display_val = str(val) if val is not None else ""
            v = tk.StringVar(value=display_val)
            e = ttk.Entry(edit, textvariable=v, width=60)
            e.grid(row=i, column=1, sticky='w', padx=4, pady=2)
            entries[c] = v

        def save_edit():
            for c, var in entries.items():
                val = var.get().strip()
                
                # Handle empty values
                if val == "" or val.lower() == "nan":
                    if c in ("–ë—Ä–æ–π–∫–∏",):
                        self.df_merged.at[df_index, c] = None
                    elif c in ("–ï–¥. –¶–µ–Ω–∞", "–°—É–º–∞", "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ–Ω –ª–∏—Å—Ç"):
                        self.df_merged.at[df_index, c] = None
                    else:
                        self.df_merged.at[df_index, c] = ""
                elif c in ("–ë—Ä–æ–π–∫–∏",):
                    try:
                        vv = int(val)
                        self.df_merged.at[df_index, c] = vv
                    except Exception:
                        self.df_merged.at[df_index, c] = None
                elif c in ("–ï–¥. –¶–µ–Ω–∞", "–°—É–º–∞", "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ–Ω –ª–∏—Å—Ç"):
                    try:
                        vv = float(str(val).replace(',', '.'))
                        self.df_merged.at[df_index, c] = vv
                    except Exception:
                        self.df_merged.at[df_index, c] = None
                else:
                    self.df_merged.at[df_index, c] = val

            edit.destroy()
            self._load_table(self.df_merged)
            
            # Auto-save to file if we have a current file path
            if self._current_file_path:
                try:
                    out_path = self._current_file_path
                    
                    # Check if file is read-only (closed protocol)
                    if is_file_readonly(Path(out_path)):
                        self.status.set("‚ö†Ô∏è –§–∞–π–ª—ä—Ç –µ –∑–∞—â–∏—Ç–µ–Ω - –ø—Ä–æ–º–µ–Ω–∏—Ç–µ –Ω–µ —Å–∞ –∑–∞–ø–∞–∑–µ–Ω–∏.")
                        return
                    
                    # Save to file
                    df_to_save = self.df_merged.copy()
                    if "–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞" in df_to_save.columns:
                        df_to_save["–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞"] = pd.to_datetime(df_to_save["–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞"], errors="coerce")
                    
                    with pd.ExcelWriter(out_path, engine="openpyxl") as writer:
                        df_to_save.to_excel(writer, index=False, sheet_name="Sheet1")
                    
                    try:
                        _apply_date_format_xlsx(out_path, header_name="–î–∞—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–∞–≤–∫–∞")
                    except Exception:
                        pass
                    
                    self.status.set(f"‚úÖ –ó–∞–ø–∞–∑–µ–Ω–æ –≤ {Path(out_path).name}")
                except Exception as e:
                    self.status.set(f"‚ö†Ô∏è –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å: {e}")
            else:
                self.status.set("–†–µ–¥—ä—Ç –µ –ø—Ä–æ–º–µ–Ω–µ–Ω (–∏–∑–ø–æ–ª–∑–≤–∞–π '–ó–∞–ø–∞–∑–∏ –∫–∞—Ç–æ...' –∑–∞ –¥–∞ –∑–∞–ø–∏—à–µ—à)")

        btn_save = ttk.Button(edit, text="–ó–∞–ø–∏—à–∏", command=save_edit)
        btn_save.grid(row=len(columns), column=0, columnspan=2, pady=6)


if __name__ == "__main__":
    # IMPORTANT: Windows-only DPI tweak; do NOT run on macOS/Linux
    if os.name == "nt":
        try:
            import ctypes
            ctypes.windll.shcore.SetProcessDpiAwareness(1)
        except Exception:
            pass

    app = App()
    app.mainloop()
